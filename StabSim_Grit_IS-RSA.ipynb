{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata, ttest_rel, ttest_1samp\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn.maskers import NiftiLabelsMasker\n",
    "from nilearn.plotting import plot_glass_brain, plot_stat_map, view_img, view_img_on_surf\n",
    "\n",
    "from nltools.data import Brain_Data, Adjacency\n",
    "from nltools.mask import roi_to_brain, expand_mask\n",
    "from nltools.stats import fdr, threshold\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import datalad.api as dl\n",
    "\n",
    "from copy import deepcopy\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "from nltools.utils import get_resource_path\n",
    "from nltools.file_reader import onsets_to_dm\n",
    "from nltools.data import Design_Matrix\n",
    "from nltools.mask import create_sphere\n",
    "from nltools.mask import expand_mask, collapse_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## bring in behavior data\n",
    "\n",
    "data_dir = '#directory path'\n",
    "behav_data = pd.read_csv(os.path.join(data_dir, '#behav file name.csv'), sep = ',') # file should contain sub & behav scores\n",
    "behav_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_data = behav_data[\"sub\"]\n",
    "subj_list = subj_data\n",
    "\n",
    "subj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bring in FC similarity data \n",
    "    # should be symmetrical, n x n (n is number of sub) format\n",
    "    # contain every pairwise similarity comparison with others (diagonal should be 1)\n",
    "data = pd.read_csv(os.path.join(data_dir,'#similarity file name.csv'), header=None, index_col=None, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualization\n",
    "data_np = np.array(data)\n",
    "fconn = Adjacency(data_np, matrix_type = 'similarity')\n",
    "\n",
    "fconn.plot(cmap='RdYlBu_r') \n",
    "plt.savefig('fconn.jpg', format='jpeg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IS-RSA ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run with AnnaK framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav = behav_data[\"GRIT_total\"]\n",
    "behav_rank = rankdata(behav) # convert the raw scores to ranks\n",
    "\n",
    "def sort_square_mtx(mtx, behav_vct):\n",
    "    \"\"\"\n",
    "    Sorts rows/columns of a matrix according to a separate vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    inds = behav_vct.argsort()\n",
    "    mtx_sort = mtx\n",
    "    mtx_sort = mtx_sort[inds, :]\n",
    "    mtx_sort = mtx_sort[:, inds]\n",
    "    \n",
    "    return mtx_sort\n",
    "\n",
    "def scale_mtx(mtx):\n",
    "    \"\"\"\n",
    "    Scales a matrix to be between 0 and 1.\n",
    "    \"\"\"\n",
    "    return (mtx-np.min(mtx))/(np.max(mtx)-np.min(mtx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with AnnaK framework ###\n",
    "\n",
    "n_subs = len(subj_data)\n",
    "behav_sim_annak = np.zeros((n_subs, n_subs))\n",
    "\n",
    "for i in range(n_subs):\n",
    "    for j in range(n_subs):\n",
    "        if i < j:\n",
    "            sim_ij = np.mean([behav_rank[i], behav_rank[j]])/n_subs\n",
    "            behav_sim_annak[i,j] = sim_ij\n",
    "            behav_sim_annak[j,i] = sim_ij\n",
    "        elif i==j:\n",
    "            behav_sim_annak[i,j] = 1\n",
    "\n",
    "behav_sim_annak = Adjacency(behav_sim_annak, matrix_type='similarity')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(13,5))\n",
    "behav_sim_annak.plot(axes=ax1)\n",
    "ax1.set_title(\"Behavioral similarity matrix before sorting\", fontsize=16)\n",
    "\n",
    "sns.heatmap(sort_square_mtx(behav_sim_annak.squareform(), behav), ax = ax2, square=True)\n",
    "ax2.set_title(\"Behavioral similarity matrix after sorting\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IS-RSA r-value\n",
    "\n",
    "isrsa_annak = similarity_matrix.similarity(behav_sim_annak, metric='spearman', n_permute=1, n_jobs=1)['correlation']\n",
    "isrsa_annak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation test\n",
    "\n",
    "stats = similarity_matrix.similarity(behav_sim_annak, metric='spearman', n_permute=5000, n_jobs=-1)\n",
    "isrsa_r = stats['correlation']\n",
    "isrsa_p = stats['p']\n",
    "\n",
    "print(isrsa_r, isrsa_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Lesion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run with Shen 268 atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bring in FC data\n",
    "\n",
    "data = []\n",
    "for subj in subj_list:\n",
    "    sub_data = []\n",
    "    sub_data.append(pd.read_csv(os.path.join(data_dir, 'connectome',f'{subj}_FC_000.csv'), header=None, index_col=None, sep = ','))\n",
    "    sub_data = pd.concat(sub_data)\n",
    "    data.append(sub_data.values)\n",
    "data = np.array(data)\n",
    "\n",
    "print(data.shape)\n",
    "n_subs, n_nodesx, n_nodesy = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bring in network label for each node\n",
    "\n",
    "shen_label = pd.read_csv(os.path.join(data_dir, 'shen_268_10NETWORK.csv')) # can be any other atlas\n",
    "shen_node = shen_label[\"Node\"] # column name for node\n",
    "shen_nodenet = shen_label[\"10_Network\"] # column name for network label of each node\n",
    "\n",
    "shen_node = np.array(shen_node)\n",
    "print(shen_node.shape)\n",
    "shen_nodenet = np.array(shen_nodenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### leave within-network functional connectivities only ###\n",
    "\n",
    "network_n = []\n",
    "\n",
    "for sub in range(len(subj_list)):\n",
    "    subconn = data[sub]\n",
    "    subnet1 = []\n",
    "    for kx in range(268):\n",
    "        for ky in range(268):\n",
    "            if shen_nodenet[kx] == shen_nodenet[ky] == 1 and kx > ky: # leave functional connectivites within a given(here, 1) network\n",
    "                pass\n",
    "            elif kx > ky:\n",
    "                subnet1.append(subconn[kx, ky])\n",
    "    network_n.append(subnet1)\n",
    "            \n",
    "for sub in range(len(network_n)):\n",
    "    network_n[sub] = np.reshape(network_n[sub], (-1, 1)) # 2d array, matrix\n",
    "\n",
    "network_n = np.array(network_n)\n",
    "\n",
    "network_n.shape\n",
    "    # output should be (number of sub, number of functional connectivities within a given network, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### connectome similarity matrix, metric = correlation ###\n",
    "\n",
    "similarity_matrix = Adjacency(1-pairwise_distances(network_n[:, :, 0], metric='correlation'), matrix_type='similarity')\n",
    "similarity_matrix.plot(cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then run ISRSA above from here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
